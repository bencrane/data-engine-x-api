# Post-Mortem: Experience Key Dedup Failure on person_work_history

**Date:** 2026-02-25
**Severity:** High. Dedup was incomplete. Duplicate rows remain. Unique index provides false confidence.

---

## Summary

We attempted to add deduplication to `core.person_work_history` (~2.6M rows) by populating an `experience_key` hash column, removing duplicates, and adding a unique index. The dedup appeared successful (459K rows deleted, unique_keys = total_rows verified) but was fundamentally flawed: **2.17M rows already had experience_key values from an earlier process using a different formula.** Phase 2 only filled NULL keys, leaving the old stale keys in place. Identical records with different keys were not detected as duplicates.

---

## What Happened (Timeline)

### Phase 1 (Succeeded)
- Added generated columns `title_normalized` on `person_work_history` and `raw_job_title_normalized` on `job_title_lookup`
- Added indexes on both
- No issues

### Phase 2 (Partially Failed)

**Step 1: Populate experience_key**
- Formula: `MD5(linkedin_url || '::' || COALESCE(company_domain, company_name, '') || '::' || LOWER(TRIM(title)) || '::' || start_date)`
- The UPDATE only targeted rows where `experience_key IS NULL`
- Result: 0 rows updated — **all rows already had experience_key values** from a prior process
- This should have been a red flag but was not caught

**Step 2: Identify duplicates**
- Found 362,509 duplicate groups (459,644 extra rows)
- These were rows where the OLD keys happened to match

**Step 3: Delete duplicates**
- Deleted 459,644 rows
- The deletions were correct for the rows they caught — same key = same record
- But missed an unknown number of duplicates where the old keys diverged for identical records

**Step 4: Unique index**
- Created successfully
- Verified total_rows = unique_keys
- This verification was misleading — it confirmed uniqueness of the OLD keys, not uniqueness of the actual records

### Post-Phase 2 Discovery

**Problem 1: Stale keys**
- 2,169,982 rows have experience_key values that do NOT match the canonical formula when recomputed today
- The old keys were generated by a different process/formula at different times
- Records that are logically identical have different keys

**Problem 2: Ongoing duplicates**
- Phase 3A (migration from person_experience) inserted new rows with experience_keys computed from the canonical formula
- These new keys don't collide with old stale keys for the same record
- The unique index doesn't block them because the keys are different
- Example: same person (naitikpanchal), same company (womennovators.com), same title (Mentor), same start_date — two rows with different experience_keys

**Problem 3: Multiple current experiences**
- Many people have 2-20+ records with `is_current = true`
- Some are genuine (person holds multiple roles) but many are duplicates that survived the incomplete dedup
- For alumni of SecurityPal/WithCoverage/Radar/Forethought customers: 2,727 people have 1 current (correct), 9,184 have 2-5, 474 have 6-20, 45 have 20+

---

## Root Cause

The `experience_key` column already existed on the table and was populated by a prior process (likely the old `sync_person_experience_to_core` trigger or an earlier migration attempt). Phase 2 was designed to fill NULLs, not recompute existing values. Since no rows had NULL keys, Phase 2 effectively did nothing for key generation — it only ran the dedup on the old inconsistent keys.

The directive should have included a verification step: "check if existing experience_key values match the canonical formula" before proceeding to dedup.

---

## What Needs to Happen (For Next Agent)

### Step 1: Drop the unique index on experience_key
```sql
DROP INDEX IF EXISTS idx_pwh_experience_key;
```
The current index is based on stale keys and blocks the re-key.

### Step 2: Recompute ALL experience_keys
Batched UPDATE across all rows (not just NULLs). Records without `company_domain` get NULL (excluded from dedup until domain is populated):
```sql
UPDATE core.person_work_history
SET experience_key = CASE
  WHEN company_domain IS NOT NULL THEN
    MD5(
      COALESCE(linkedin_url, '') || '::' ||
      company_domain || '::' ||
      COALESCE(LOWER(TRIM(title)), '') || '::' ||
      COALESCE(start_date::TEXT, '')
    )
  ELSE NULL
END
WHERE id IN (SELECT id FROM core.person_work_history LIMIT 50000 OFFSET {N});
```
Run in batches of 50K. Report after each batch.

### Step 3: Re-dedup
Same process as Phase 2 Step 2-3: find duplicate experience_keys, keep most recent created_at, delete the rest. Expect significantly more duplicates this time.

### Step 4: Re-create unique index
```sql
CREATE UNIQUE INDEX CONCURRENTLY idx_pwh_experience_key
ON core.person_work_history(experience_key);
```

### Step 5: Verify
- total_rows = unique_keys
- Spot-check known duplicates (e.g., naitikpanchal/Womennovator) to confirm they collapsed

---

## What About Records Already Deleted?

The 459K rows deleted in the original Phase 2 were correct deletions — they had matching keys AND matching data. No data was lost that shouldn't have been. The issue is that more duplicates exist that weren't caught, not that wrong rows were deleted.

---

## What About the person_experience → person_work_history Migration?

Phase 3A pushed records from `extracted.person_experience` using `ON CONFLICT (experience_key) DO NOTHING`. Because the keys were stale, some records that should have been conflicts were inserted as new rows instead. After the re-key + re-dedup, these will be caught.

To check which person_experience records have been pushed (independent of experience_key):
```sql
SELECT COUNT(*)
FROM extracted.person_experience pe
WHERE pe.company_domain IS NOT NULL
  AND NOT EXISTS (
    SELECT 1 FROM core.person_work_history pwh
    WHERE pwh.source_id = pe.id
  );
```
The `source_id` column links work_history rows to their person_experience source, regardless of hash state.

---

## The Trigger

The `trg_sync_person_experience` trigger on `extracted.person_experience` has been **disabled** (status: D). It was a blind INSERT with no dedup, no job title matching, and no domain filtering. It should remain disabled until it is rebuilt with proper ON CONFLICT logic using the canonical experience_key formula.

---

## Key Files

- `core.person_work_history` — the table with the problem
- `extracted.person_experience` — the source table for migration
- `reference.job_title_lookup` — the reference table for title matching (separate concern, not broken)
- `docs/directives-hq/DIRECTIVE_JOB_TITLE_MATCHING_PHASE_1.md` — Phase 1 (succeeded)
- `docs/directives-hq/DIRECTIVE_JOB_TITLE_MATCHING_PHASE_2.md` — Phase 2 (partially failed)
- `docs/directives-hq/DIRECTIVE_JOB_TITLE_MATCHING_PHASE_3.md` — Phase 3 (migration, in progress)

---

## Lessons

1. **Always verify existing data before assuming columns are empty.** Phase 2 assumed experience_key was NULL everywhere. It wasn't.
2. **Recompute, don't fill.** When adding a canonical hash, always recompute ALL rows, not just NULLs. Old values from different formulas are worse than NULLs.
3. **Verify dedup with business logic, not just key counts.** "total_rows = unique_keys" only proves key uniqueness, not record uniqueness. Should have spot-checked known duplicate records.
4. **Don't trust prior state.** The experience_key column existed from earlier work. Its values were not trustworthy. Should have been treated as corrupt from the start.
